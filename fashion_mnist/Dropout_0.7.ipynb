{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhtNLTqfKV3-"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib \n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "0iLiMHV5KWnR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fashion MNIST 데이터셋 로드\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# 데이터 전처리\n",
        "train_images = train_images.reshape(-1, 28, 28, 1)\n",
        "test_images = test_images.reshape(-1, 28, 28, 1)\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print(train_labels.shape, test_labels.shape)"
      ],
      "metadata": {
        "id": "73ZBnP93KaBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet model architecture\n",
        "model = Sequential()\n",
        "\n",
        "# 1st Convolutional Layer\n",
        "model.add(Conv2D(filters=96, input_shape=(28,28,1), kernel_size=(11,11), strides=(4,4), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# 2nd Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# 3rd Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 4th Convolutional Layer\n",
        "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# 5th Convolutional Layer\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same')) \n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same'))\n",
        "\n",
        "# Fully Connected layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4096, input_shape=(32,32,3))) \n",
        "model.add(BatchNormalization()) \n",
        "model.add(Activation('relu'))\n",
        "\n",
        "# Add Dropout to prevent overfitting\n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model.add(Dense(4096)) \n",
        "model.add(BatchNormalization()) \n",
        "model.add(Activation('relu')) # Add Dropout \n",
        "model.add(Dropout(0.7))\n",
        "\n",
        "# Output Layer\n",
        "model.add(Dense(10)) \n",
        "model.add(BatchNormalization()) \n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# Model Summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "UdQ763jJKb1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.001), \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_images, train_labels, epochs=90, \n",
        "                    validation_data=(test_images, test_labels))\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "id": "TR1pudeKKeWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fashion mnist, dropout0.7\n",
        "\n",
        "accuracy = model.evaluate(test_images, test_labels, verbose=1)\n",
        "print('Test loss:', accuracy[0])\n",
        "print('Test accuracy:', accuracy[1])"
      ],
      "metadata": {
        "id": "e4ydVSnPLU0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 12))\n",
        "\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "plt.subplots_adjust(hspace=0.3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hxO8T-MWK_QA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}